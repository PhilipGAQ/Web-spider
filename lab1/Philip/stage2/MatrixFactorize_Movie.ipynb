{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           User    Movie  Rate                       Time       Tag\n",
      "1       1386692  1986338     3  2011-02-25T08:29:20+08:00   美国,2011\n",
      "2       1386692  4268598     5  2011-02-14T10:05:42+08:00   日本,2011\n",
      "3       1386692  1851857     4  2011-02-11T16:06:22+08:00   美国,2011\n",
      "4       1386692  4023638     4  2011-02-10T19:25:12+08:00   英国,2011\n",
      "5       1386692  1305903     3  2011-02-10T19:24:06+08:00  加拿大,2011\n",
      "...         ...      ...   ...                        ...       ...\n",
      "714934  1379646  1309004     5  2007-01-16T20:58:29+08:00       NaN\n",
      "714967  1379646  1783772     5  2007-01-14T01:46:16+08:00       NaN\n",
      "714984  1379646  1291859     5  2007-01-14T01:30:09+08:00       NaN\n",
      "714993  1379646  1484091     5  2007-01-14T01:23:55+08:00       NaN\n",
      "715018  1379646  1291836     4  2007-01-12T21:42:48+08:00       NaN\n",
      "\n",
      "[523648 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 读loaded_data取保存的 CSV 文件\n",
    "loaded_data = pd.read_csv('data\\\\movie_score.csv')\n",
    "\n",
    "# 显示加载的数据\n",
    "#print(loaded_data)\n",
    "loaded_data=loaded_data[loaded_data['Rate'] != 0]\n",
    "print(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 处理加载的数据，得到item、user和star信息。\n",
    "#合并相同的userids和itemsids\n",
    "user_ids=loaded_data[\"User\"].unique()\n",
    "item_ids=loaded_data[\"Movie\"].unique()\n",
    "#创建user to row的字典\n",
    "user_to_row ={user_id : idx for idx, user_id in enumerate(user_ids)}\n",
    "item_to_row ={item_id : idx for idx, item_id in enumerate(item_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RatingDataset(Dataset):\n",
    "    def __init__(self,data,user_to_row,item_to_row):\n",
    "        self.data=data\n",
    "        #self.user_item_matrix=user_item_matrix\n",
    "        self.user_to_row=user_to_row\n",
    "        self.item_to_row=item_to_row\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        user = self.user_to_row[row['User']]\n",
    "        movie = self.item_to_row[row['Movie']]\n",
    "        rating = row['Rate'].astype('float32')\n",
    "        return user, movie, rating\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dim为超参数，由用户定义\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self,num_users,num_movies,embedding_dim):\n",
    "        super(MatrixFactorization,self).__init__()\n",
    "        #词嵌入技术，将user和item分别嵌入为向量\n",
    "        self.user_embeddings=nn.Embedding(num_users,embedding_dim)\n",
    "        self.movie_embeddings=nn.Embedding(num_movies,embedding_dim)\n",
    "\n",
    "    def forward(self, user,movie):\n",
    "        # 输出即为user矩阵和movie矩阵相乘得到的结果\n",
    "        user_embedding=self.user_embeddings(user)\n",
    "        movie_embedding=self.movie_embeddings(movie)\n",
    "        return (user_embedding*movie_embedding).sum(dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 创建训练集和测试集的数据集对象和数据加载器\n",
    "train_data, test_data = train_test_split(loaded_data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = RatingDataset(train_data, user_to_row, item_to_row)\n",
    "test_dataset = RatingDataset(test_data, user_to_row, item_to_row)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4096, shuffle=True, drop_last = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4096, shuffle=False, drop_last = True)\n",
    "\n",
    "embedding_dim=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "num_users=len(user_ids)\n",
    "num_movies=len(item_ids)\n",
    "print(num_users)\n",
    "print(num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MatrixFactorization(num_users,num_movies,embedding_dim).to(device)\n",
    "criterion=nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 27.623929977416992\n",
      "Epoch 2/10, Loss: 15.97860050201416\n",
      "Epoch 3/10, Loss: 4.323372840881348\n",
      "Epoch 4/10, Loss: 2.2262110710144043\n",
      "Epoch 5/10, Loss: 1.648421049118042\n",
      "Epoch 6/10, Loss: 1.2159852981567383\n",
      "Epoch 7/10, Loss: 1.0376439094543457\n",
      "Epoch 8/10, Loss: 0.9023718237876892\n",
      "Epoch 9/10, Loss: 0.852106511592865\n",
      "Epoch 10/10, Loss: 0.7923122644424438\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "num_epochs = 10\n",
    "lambda_b=0.001\n",
    "lambda_u=0.001\n",
    "for epoch in range(num_epochs):\n",
    "    for user, movie, rating in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(user, movie)\n",
    "        loss = criterion(output, rating) + lambda_u * model.user_embeddings.weight.norm(2) + lambda_b * model.movie_embeddings.weight.norm(2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # 监控损失或其他性能指标\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.7214122080802917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()  # 将模型设置为评估模式，不进行梯度更新\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():  # 不计算梯度\n",
    "    for user, movie, rating in test_dataloader:\n",
    "        output = model(user, movie)\n",
    "        loss = criterion(output, rating)\n",
    "        #print(f\"Test Loss: {loss}\")\n",
    "        test_loss += loss.item()\n",
    "\n",
    "# 计算测试性能指标，例如均方误差或其他指标\n",
    "average_test_loss = test_loss / len(test_dataloader)\n",
    "print(f\"Average Test Loss: {average_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos similarity=0.9762505820468013\n",
      "NDCG_score=0.9457839910554704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "#使用余弦相似度计算预测顺序和实际数据的差距\n",
    "model.eval()  # 将模型设置为评估模式，不进行梯度更新\n",
    "num_users=int(num_users)\n",
    "num_movies=int(num_movies)\n",
    "real_score_array=np.zeros((num_users,num_movies))\n",
    "pred_score_array=np.zeros((num_users,num_movies))\n",
    "\n",
    "with torch.no_grad():  # 不计算梯度\n",
    "    for user, movie, rating in test_dataloader:\n",
    "        pred = model(user, movie)\n",
    "        for i in range(4096):\n",
    "            real_score_array[int(user[i]),int(movie[i])]=int(rating[i])\n",
    "            pred_score_array[int(user[i]),int(movie[i])]=float(pred[i])\n",
    "cos_sum=0\n",
    "ndcg_sum=0\n",
    "#抽取前100组user\n",
    "for i in range(100):\n",
    "    #cal ndcg\n",
    "    ndcg=ndcg_score(real_score_array[i].reshape(1,-1),pred_score_array[i].reshape(1,-1))\n",
    "    ndcg_sum=ndcg_sum+ndcg\n",
    "    vec1=np.argsort(real_score_array[i])\n",
    "    vec2=np.argsort(pred_score_array[i])\n",
    "    cos_sim = vec1.dot(vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    cos_sum=cos_sum+cos_sim\n",
    "print(f\"cos similarity={cos_sum/100}\\nNDCG_score={ndcg_sum/100}\")\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
